---
title: "Lab 13"
author: "Adam Hayes, Erin Omyer, Richard Park, Jasmine Sanchez"
date: "4/17/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r}
library(tidyverse)
trafficData <- read_csv("TrafficDeathsPer1000.csv")%>%
  rename(Country = "Traffic mortality per 100,000, age adjusted")
populationDensity <- read_csv("PopulationDensity.csv")%>%
  rename(Country = "Population density (per square km)")

trafficDataReal <- trafficData %>%
  select(Country,`2002`,`2004`)
trafficDataReal$`2002` <- as.numeric(trafficDataReal$`2002`)
trafficDataReal$`2004` <- as.numeric(trafficDataReal$`2004`)

populationDensityReal <- populationDensity %>%
  select(Country,`2002`,`2004`)
populationDensityReal$`2002` <- as.numeric(populationDensityReal$`2002`)
populationDensityReal$`2004` <- as.numeric(populationDensityReal$`2004`)


mergedData <- trafficDataReal %>%
  inner_join(populationDensityReal, by = "Country", suffix = c(".trafficDeath",".popDensity"))

mergedDataReal <- na.omit(mergedData)
```

###Overall Question: Do traffic deaths increase with higher population density?

####Importance:

####Our Data:
Our team used 2 datasets, one representing traffic deaths per 100,000 people in various countries throughout the years, and the other representing population density in various countries throughout the years.  We decided to only look at the years 2002 and 2004 for both datasets because those years had the most complete data for each.  We then merged the two datasets by using an inner_join() the country name, and omitted all countries that had any NA values.  This gave us a complete dataset showing each country's traffic deaths and population density side by side for the years 2002 and 2004.

####Conclusion:




###Adam's Findings

This map_dbl function is calculating the mean of each column in my trafficDataAdam dataset which represents the mean number of traffic deaths per 100,000 people per country in 2002 and 2004.
```{r, include = TRUE}

trafficDataAdam <- na.omit(trafficDataReal) %>%
  select(`2002`,`2004`)
  
as_tibble(trafficDataAdam)%>%
  map_dbl(mean)
```


This function accepts a data frame and a different function, and loops through the data frame, applying the inputted function to each column.  In my case I took my merged data set with each country's traffic deaths per 100,000 ppl in 2002 and 2004, and population density in 2002 and 2004.  I calculated the mean and standard deviation of each column, showing a good distribution of the data in each column.
```{r, include=TRUE}
mergedDataAdam <- mergedDataReal %>%
  select(2:5)

myColSummary <- function(df,myFun){
  myOut <- vector("double", length(df))
  for(i in seq(df)){
    myOut[i] <- myFun(df[[i]])
  }
  return(myOut)
}
myColSummary(mergedDataAdam,mean)
myColSummary(mergedDataAdam,sd)

```

####Permutation Question: Do the years 2002 and 2004 have statistically significant differences in their mean ratio of population density to traffic deaths? And do the year labels matter?
Null: Difference In Means between(Ratio.2004 and Ratio.2002) = Difference In Means between(Random groupings of the 2)

Alternate:Difference In Means between(Ratio.2004 and Ratio.2002) != Difference In Means between(Random groupings of the 2)

Test Statistic: Sample Mean

```{r}
AdamData <- mergedDataReal %>%
  mutate(Ratio.2002 = `2002.popDensity` / `2002.trafficDeath`, 
         Ratio.2004 = `2004.popDensity` / `2004.trafficDeath`)
#higher the ratio, lower the traffic deaths relative to population density

mean2002 <- AdamData %>%
  select(Ratio.2002)%>%
  summarise(mean = mean(Ratio.2002))
mean2004 <- AdamData %>%
  select(Ratio.2004)%>%
  summarise(mean = mean(Ratio.2004))

differenceActual = mean2004 - mean2002

testData <- AdamData %>%
  select(Ratio.2002, Ratio.2004)

combined <- c(testData$Ratio.2002, testData$Ratio.2004)

permutationAdam <- function(perms = 1000, values, n1)
{
  outputMean <- vector("double", perms)
  for (i in c(1:perms))
  {
    # Randomly separate vector "values" into disjoint 
    # groups of size "n1" and "length(values) - n1" respectively
    
    vector1 <- sample(values, n1)
    vector2 <- setdiff(values, vector1)

    # Compute the sample means for the two groups from 
    firstMean <- mean(vector1)
    secondMean <- mean(vector2)
    
    # Compute the difference in sample means
    meanDifference <- firstMean - secondMean
    
    outputMean[i] <- meanDifference
  }
  # Return new updated vector, created in step 1
  return(outputMean)
}

resultAdam <- permutationAdam(1000,combined,150)

ggplot()+
  geom_histogram(aes(x=resultAdam), col = "red")+
  geom_vline(xintercept = 1.33, col = "blue")+
  labs(title="Distribution of Difference in Means of random groupings of Ratio.2004 and Ratio.2002")+
  xlab("Difference")

percentileData <- sum(resultAdam<1.33)/1000
percentileData
```

####Conclusion
First, I created 2 new variables representing the ratio of population density to traffic deaths per 100,000 for each country, the two variables represented these ratios for 2002 and 2004.  I then calculated the mean ratio for each year, and found the difference, noticing that 2004 had a slightly higher mean ratio meaning that year countries had less traffic deaths relative to population density on average.  My actual difference in means of the two groups was 1.33, represented by the blue vertical line in the histogram.  As a percentile, it is represented by the decimal number below the histogram. Looking at the graph influences me to accept the alternate hypothesis because it seems as if the distribution of mean differences is so spread out, it is not easily concluded that the vertical line is the center of the data. However, the percentile shows that the actual difference in means of the two groups is very close to the 50th percentile of the permutation data, so therefore I would lean towards accepting the null hypothesis.


###Richard's Findings

The map_dbl function is used here to calculate the mean of each column in my TrafficRichard dataset which represents the median number of traffic deaths per 100,000 people per country in 2002 and 2004.

```{r, include = TRUE}

TrafficRichard <- na.omit(trafficDataReal) %>%
  select(`2002`,`2004`)

as_tibble(TrafficRichard)%>%
  map_dbl(median)
```

The function here accepts a data frame and a different function. From there, it loops through the data frame, applying the inputted function to each column.  In this case, I took my merged data set with each country's traffic deaths per 100,000 ppl in 2002 and 2004, and population density in 2002 and 2004.  I calculated the median and standard deviation of each column, showing a good distribution of the data in each column.

```{r, include=TRUE}
mergedRichardData <- mergedDataReal %>%
  select(2:5)

myColSummary <- function(df,myFun){
  myOut <- vector("double", length(df))
  for(i in seq(df)){
    myOut[i] <- myFun(df[[i]])
  }
  return(myOut)
}
myColSummary(mergedRichardData,median)
myColSummary(mergedRichardData,sd)

```

####Permutation
Null: Difference in Medians between(Ratio.2004 and Ratio.2002) = Difference in Medians between(Random groupings of the 2)

Alternate:Difference in Medians between(Ratio.2004 and Ratio.2002) != Difference in Medians between(Random groupings of the 2)

Test Statistic: Sample Median

```{r}

```

###Erin's Findings

The map_dbl function is used here to calculate the mean of each column in my trafficErin dataset which represents the mean number of traffic deaths per 100,000 people per country in 2002 and 2004.

```{r, include = TRUE}
trafficErin <- na.omit(trafficDataReal) %>%
  select(`2002`,`2004`)

as_tibble(trafficErin)%>%
  map_dbl(mean)
```

This function accepts a data frame and a different function, and loops through the data frame, applying the inputted function to each column.  In my case I took my merged data set with each country's traffic deaths per 100,000 ppl in 2002 and 2004, and population density in 2002 and 2004.  I calculated the difference from 2004 to 2002 for population density and then did the same thing for traffic deaths and then calculated the mean for those columns. 

```{r, include=TRUE}
mergedErin <- mergedDataReal %>%
  select(2:5)

myColSummary <- function(df,myFun){
  myOut <- vector("double", length(df))
  for(i in seq(df)){
    myOut[i] <- myFun(df[[i]])
  }
  return(myOut)
}
myColSummary(mergedErin,mean)
myColSummary(mergedErin,sd)

```

####Permutation Question:Do the mean differences between the years 2002 and 2004 for Traffic Deaths and Pop. Density have a statistically significant difference in their mean ratio?

Null: Difference in means between 2004 and 2002 of Population density and Traffic deaths = Difference in means between random groupings of the 2.
Alternate: Difference in means between 2004 and 2002 of Population density and Traffic deaths != Difference in means between random groupings of the 2.

Test Statistic: Sample Mean

```{r}
ErinData <- mergedDataReal %>%
  mutate(Ratio.diffTraff = `2004.trafficDeath` - `2002.trafficDeath`, Ratio.diffPop = `2004.popDensity` - `2002.popDensity`)
#show if it will increase in pop density and traffic deaths between 2004 and 2002.

differenceTrafficDeath <- ErinData %>%
  select(Ratio.diffTraff)%>%
  summarise(mean = mean(Ratio.diffTraff))
differencePopDensity <- ErinData %>%
  select(Ratio.diffPop)%>%
  summarise(mean = mean(Ratio.diffPop))

differenceActual = differenceTrafficDeath - differencePopDensity
differenceActual

testDataErin <- ErinData %>%
  select(Ratio.diffTraff, Ratio.diffPop)

combinedErin <- c(testDataErin$Ratio.diffTraff, testDataErin$Ratio.diffPop)

permutationErin <- function(perms = 1000, values, n1)
{
  outputMean <- vector("double", perms)
  for (i in c(1:perms))
  {
    # Randomly separate vector "values" into disjoint 
    # groups of size "n1" and "length(values) - n1" respectively
    
    vector1 <- sample(values, n1)
    vector2 <- setdiff(values, vector1)

    # Compute the sample means for the two groups from 
    firstMean <- mean(vector1)
    secondMean <- mean(vector2)
    
    # Compute the difference in sample means
    meanDifference <- firstMean - secondMean
    
    outputMean[i] <- meanDifference
  }
  # Return new updated vector, created in step 1
  return(outputMean)
}

resultErin <- permutationErin(1000,combinedErin,150)

ggplot()+
  geom_histogram(aes(x=resultErin), col = "pink")+
  geom_vline(xintercept = -1.33, col = "green")+
  labs(title="Distribution of the differene between Pop Density and Traffic Deaths between 2002 and 2004 means")+
  xlab("Change between 2002 and 2004 means of population density and traffic death")

percentileDataErin <- sum(resultErin < -1.33)/1000
percentileDataErin
```

####Conclusion
First, I created two new variables for the difference in numbers between traffics death between 2002 and 2004 and the difference between population density between 2002 and 2004. From the histogram shown,it displays a relatively normal distribution, meaning the population density and traffic deaths between 2002 and 2004 were remaining relatively the same. This allowed the normal distribution to occurr.There was abnormaility in calculating actual difference between the difference of the mean differences. It lead to a -1.33, which was skewed to the left on the graph. For this conclusion, I would lean towards rejecting the null hypothesis.

####Who did what?
Adam loaded in the two datasets, tidied and filtered them, and then merged them together, he then described the data in the team section.  In his individual section he investigated the ratio of population density to traffic deaths, finding the mean for each year, and running a permutation test to find out if the year labels influence the difference in means. Erin loaded in her individual section of investigating the mean difference of population density to traffic death during the years 2002 and 2004. Through this, she found the difference between the years and then took the mean of the new mutated columns, then running a permutation test to find out the effect. Overall, she thinks we should reject the null hypothesis.

